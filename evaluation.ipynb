{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from utils import misc, preprocessing, evaluation_metrics\n",
    "from call_backs import TestEmbeddingCallback\n",
    "from custom_layers.arcface_loss import ArcMarginProduct\n",
    "\n",
    "# to access cifar100\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # GENERAL\n",
    "    RANDOM_SEED = 5\n",
    "    TENSOR_LOG_DIR = 'logs'\n",
    "    SAVE_DIR = 'saved_models'\n",
    "\n",
    "    # DATA\n",
    "    INPUT_SIZE = (32,32,3)\n",
    "    NUM_CLASSES = 100 # holding out 5 classes from cifar100\n",
    "\n",
    "    # MODEL\n",
    "    OUTPUT_EMB = 64\n",
    "    MIDDLE_EMB = 256\n",
    "\n",
    "    # TRAINING\n",
    "    EPOCHS = 5#30\n",
    "    BATCH_SIZE = 32\n",
    "    LR = .0005\n",
    "\n",
    "misc.seed_everything(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# images are of correct input_size\n",
    "print('x_train shape:', x_train.get_shape())\n",
    "assert x_train.get_shape()[-3:] == config.INPUT_SIZE\n",
    "\n",
    "print('y_train shape:', y_train.get_shape())\n",
    "# y_train has only 1 label per item in tensor\n",
    "assert y_train.get_shape()[-1:] == 1\n",
    "\n",
    "# num images == num labels\n",
    "assert y_train.get_shape()[0] == x_train.get_shape()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({19: 500, 29: 500, 0: 500, 11: 500, 1: 500, 86: 500, 90: 500, 28: 500, 23: 500, 31: 500, 39: 500, 96: 500, 82: 500, 17: 500, 71: 500, 8: 500, 97: 500, 80: 500, 74: 500, 59: 500, 70: 500, 87: 500, 84: 500, 64: 500, 52: 500, 42: 500, 47: 500, 65: 500, 21: 500, 22: 500, 81: 500, 24: 500, 78: 500, 45: 500, 49: 500, 56: 500, 76: 500, 89: 500, 73: 500, 14: 500, 9: 500, 6: 500, 20: 500, 98: 500, 36: 500, 55: 500, 72: 500, 43: 500, 51: 500, 35: 500, 83: 500, 33: 500, 27: 500, 53: 500, 92: 500, 50: 500, 15: 500, 18: 500, 46: 500, 75: 500, 38: 500, 66: 500, 77: 500, 69: 500, 95: 500, 99: 500, 93: 500, 4: 500, 61: 500, 94: 500, 68: 500, 34: 500, 32: 500, 88: 500, 67: 500, 30: 500, 62: 500, 63: 500, 40: 500, 26: 500, 48: 500, 79: 500, 85: 500, 54: 500, 44: 500, 7: 500, 12: 500, 2: 500, 41: 500, 37: 500, 13: 500, 25: 500, 10: 500, 57: 500, 5: 500, 60: 500, 91: 500, 3: 500, 58: 500, 16: 500})\n"
     ]
    }
   ],
   "source": [
    "class_count = Counter(np.array(tf.reshape(y_train, [y_train.get_shape()[0],])))\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(preprocessing.normalize).map(preprocessing.arcface_format).batch(config.BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocessing.normalize).map(preprocessing.arcface_format).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from custom_layers.arcface_loss import ArcMarginProduct\n",
    "from custom_layers.subcenter_arcface_loss import SubcenterArcMarginProduct as ArcMarginProduct\n",
    "# allows 2 inputs and 2 outputs\n",
    "\n",
    "def get_debug_model(s = 10, m = .25, k = 3):\n",
    " #------------------\n",
    "    # Definition of placeholders\n",
    "    inp = tf.keras.layers.Input(shape = config.INPUT_SIZE, name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "\n",
    "    # Definition of layers\n",
    "    \n",
    "    #TODO: reasearch filters, get better understanding\n",
    "    layer_conv1 = tf.keras.layers.Conv2D(filters = 24, kernel_size = (2,2), input_shape = config.INPUT_SIZE, activation ='relu')\n",
    "    layer_pool1 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    layer_conv2 = tf.keras.layers.Conv2D(filters = 12, kernel_size = (2,2), activation ='relu')\n",
    "    layer_pool2 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    layer_flatten = tf.keras.layers.Flatten()\n",
    "    layer_dense1 = tf.keras.layers.Dense(config.MIDDLE_EMB)\n",
    "    layer_dense2 = tf.keras.layers.Dense(config.NUM_CLASSES)\n",
    "    layer_arcface = ArcMarginProduct(n_classes=config.NUM_CLASSES, s=s, m=m, k=k)\n",
    "    layer_softmax = tf.keras.layers.Softmax(dtype='float16', name='head_output')\n",
    "\n",
    "    if config.MIDDLE_EMB != config.OUTPUT_EMB:\n",
    "        layer_adaptive_pooling = tfa.layers.AdaptiveAveragePooling1D(config.OUTPUT_EMB)\n",
    "    else:\n",
    "        layer_adaptive_pooling = tf.keras.layers.Lambda(lambda x: x)  # layer with no operation\n",
    "\n",
    "    #------------------\n",
    "    # Definition of entire model\n",
    "    backbone_output = layer_conv1(inp)\n",
    "    backbone_output = layer_pool1(backbone_output)\n",
    "    backbone_output = layer_conv2(backbone_output)\n",
    "    backbone_output = layer_pool2(backbone_output)\n",
    "    embed = layer_flatten(backbone_output)\n",
    "    embed = layer_dense1(embed)\n",
    "    \n",
    "    # Training head\n",
    "    # head_output = layer_dense2(embed)\n",
    "    head_output = layer_arcface((embed,label))\n",
    "    head_output = layer_softmax(head_output)\n",
    "    \n",
    "    # Inference\n",
    "    emb_output = layer_adaptive_pooling(embed)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [(inp, label)], outputs = [head_output, emb_output]) # whole architecture\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inp1 (InputLayer)              [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 31, 31, 24)   312         ['inp1[0][0]']                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 24)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 12)   1164        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 12)    0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 588)          0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          150784      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " inp2 (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " subcenter_arc_margin_product (  (None, 100)         51200       ['dense[0][0]',                  \n",
      " SubcenterArcMarginProduct)                                       'inp2[0][0]']                   \n",
      "                                                                                                  \n",
      " head_output (Softmax)          (None, 100)          0           ['subcenter_arc_margin_product[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " adaptive_average_pooling1d (Ad  (None, 64)          0           ['dense[0][0]']                  \n",
      " aptiveAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 203,460\n",
      "Trainable params: 203,460\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "debug_model = get_debug_model(s=32, m=.15, k=2)\n",
    "debug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10\n"
     ]
    }
   ],
   "source": [
    "debug_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = config.LR),\n",
    "        loss = {'head_output':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)},\n",
    "        metrics = {'head_output':[tf.keras.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)]},\n",
    "        )\n",
    "\n",
    "steps_per_epoch = len(train_dataset) // config.BATCH_SIZE  // 20     # \"//20\" means that the lr is update every 0.1 epoch.\n",
    "validation_steps = len(test_dataset) // config.BATCH_SIZE\n",
    "if len(test_dataset) % config.BATCH_SIZE != 0:\n",
    "    validation_steps += 1\n",
    "print(steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                        #  write_graph=True,\n",
    "                        #  write_images=True,\n",
    "                        update_freq='epoch',\n",
    "                        #  profile_batch=2,\n",
    "                        #  embeddings_freq=1\n",
    "                        )\n",
    "\n",
    "#emb_callback = call_backs.EmbeddingCallback(x_test, y_test, save_dir = log_dir+'/emb/', embedding_dim = config.OUTPUT_EMB)\n",
    "emb_callback = TestEmbeddingCallback(x_test, y_test, 'logs/emb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 14ms/steploss: 8\n",
      "[20 20 20 ...  6 20 92]\n",
      "0       []\n",
      "1       []\n",
      "2       []\n",
      "3       []\n",
      "4       []\n",
      "        ..\n",
      "9995    []\n",
      "9996    []\n",
      "9997    []\n",
      "9998    []\n",
      "9999    []\n",
      "Name: nearest_neighbors, Length: 10000, dtype: object\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    0\n",
      "9996    0\n",
      "9997    0\n",
      "9998    0\n",
      "9999    0\n",
      "Name: matching_neighbors, Length: 10000, dtype: int64\n",
      "Total matches: 0\n",
      "Competition score was 0.0\n",
      "1563/1563 [==============================] - 66s 40ms/step - loss: 8.3479 - head_output_loss: 8.3479 - head_output_sparse_categorical_accuracy: 0.0000e+00 - head_output_sparse_top_k_categorical_accuracy: 8.0000e-05 - val_loss: 7.9910 - val_head_output_loss: 7.9910 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = debug_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,#config.EPOCHS,\n",
    "        validation_steps = validation_steps,\n",
    "        validation_data = test_dataset,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard_callback, emb_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test examples: 10000\n",
      "313/313 [==============================] - 4s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Test examples:\",len(x_test))\n",
    "pred_class, pred_emb = debug_model.predict((x_test, y_test))  # I don't like this, (hacky way would be y test of -1s if non given)\n",
    "\n",
    "true_class = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 20 20 ...  6 20 92]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_idx</th>\n",
       "      <th>true_class</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>[7.580856, 46.504192, -5.5226183, -3.2795591, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>[18.986912, 17.552973, 5.0773163, -13.147473, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>[20.06215, 16.800026, -15.553776, -5.8193264, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>[18.893036, 52.9505, -12.67054, -12.761052, 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>[-0.4009695, 20.429302, -22.221426, -33.22135,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoy_idx  true_class  pred_class  \\\n",
       "0          0          49          20   \n",
       "1          1          33          20   \n",
       "2          2          72          20   \n",
       "3          3          51          54   \n",
       "4          4          71          70   \n",
       "\n",
       "                                           embedding  \n",
       "0  [7.580856, 46.504192, -5.5226183, -3.2795591, ...  \n",
       "1  [18.986912, 17.552973, 5.0773163, -13.147473, ...  \n",
       "2  [20.06215, 16.800026, -15.553776, -5.8193264, ...  \n",
       "3  [18.893036, 52.9505, -12.67054, -12.761052, 7....  \n",
       "4  [-0.4009695, 20.429302, -22.221426, -33.22135,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_data, tree = evaluation_metrics.test_embeddings(true_class,pred_class,pred_emb,config.NUM_CLASSES)\n",
    "\n",
    "emb_df = pd.DataFrame(embedding_data)\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['length']=emb_df['embedding'].apply(evaluation_metrics.dist_to_origin)\n",
    "emb_df['normed_embeddings']=emb_df['embedding']/emb_df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.build(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "emb_df['nearest_neighbors'] = emb_df['annoy_idx'].apply(lambda row: evaluation_metrics.n_neighbors(row,tree))\n",
    "emb_df['neighbor_classes'] = emb_df.apply(lambda row: evaluation_metrics.neighbor_classes(row,emb_df,true_classes=True), axis=1)\n",
    "emb_df['neighbor_pred_classes'] = emb_df.apply(lambda row: evaluation_metrics.neighbor_classes(row,emb_df,true_classes=False), axis=1)\n",
    "emb_df['matching_neighbors'] = emb_df.apply(lambda row: evaluation_metrics.matching_neighbors(row,true_classes=True), axis=1)\n",
    "emb_df['matching_neighbor_preds'] = emb_df.apply(lambda row: evaluation_metrics.matching_neighbors(row,true_classes=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_idx</th>\n",
       "      <th>true_class</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>embedding</th>\n",
       "      <th>length</th>\n",
       "      <th>normed_embeddings</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>neighbor_classes</th>\n",
       "      <th>neighbor_pred_classes</th>\n",
       "      <th>matching_neighbors</th>\n",
       "      <th>matching_neighbor_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>[7.580856, 46.504192, -5.5226183, -3.2795591, ...</td>\n",
       "      <td>183.407761</td>\n",
       "      <td>[0.041333344, 0.25355628, -0.030111149, -0.017...</td>\n",
       "      <td>[6311, 7039, 295, 8215, 4123]</td>\n",
       "      <td>[12, 41, 72, 49, 23]</td>\n",
       "      <td>[20, 20, 20, 20, 20]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>[18.986912, 17.552973, 5.0773163, -13.147473, ...</td>\n",
       "      <td>112.269287</td>\n",
       "      <td>[0.16911937, 0.15634705, 0.045224447, -0.11710...</td>\n",
       "      <td>[9349, 5924, 8424, 1647, 3061]</td>\n",
       "      <td>[33, 7, 80, 27, 38]</td>\n",
       "      <td>[20, 20, 20, 20, 20]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>[20.06215, 16.800026, -15.553776, -5.8193264, ...</td>\n",
       "      <td>149.336716</td>\n",
       "      <td>[0.1343417, 0.11249763, -0.10415239, -0.038967...</td>\n",
       "      <td>[143, 51, 9836, 6406, 6063]</td>\n",
       "      <td>[6, 37, 89, 17, 31]</td>\n",
       "      <td>[20, 20, 20, 20, 20]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>[18.893036, 52.9505, -12.67054, -12.761052, 7....</td>\n",
       "      <td>163.814301</td>\n",
       "      <td>[0.11533203, 0.32323492, -0.07734697, -0.07789...</td>\n",
       "      <td>[4498, 9370, 1206, 8154, 6830]</td>\n",
       "      <td>[5, 85, 4, 74, 44]</td>\n",
       "      <td>[20, 20, 5, 54, 20]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>[-0.4009695, 20.429302, -22.221426, -33.22135,...</td>\n",
       "      <td>153.165390</td>\n",
       "      <td>[-0.0026178858, 0.13338067, -0.14508125, -0.21...</td>\n",
       "      <td>[3005, 6315, 5276, 7689, 5308]</td>\n",
       "      <td>[0, 78, 92, 71, 1]</td>\n",
       "      <td>[70, 54, 70, 53, 70]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoy_idx  true_class  pred_class  \\\n",
       "0          0          49          20   \n",
       "1          1          33          20   \n",
       "2          2          72          20   \n",
       "3          3          51          54   \n",
       "4          4          71          70   \n",
       "\n",
       "                                           embedding      length  \\\n",
       "0  [7.580856, 46.504192, -5.5226183, -3.2795591, ...  183.407761   \n",
       "1  [18.986912, 17.552973, 5.0773163, -13.147473, ...  112.269287   \n",
       "2  [20.06215, 16.800026, -15.553776, -5.8193264, ...  149.336716   \n",
       "3  [18.893036, 52.9505, -12.67054, -12.761052, 7....  163.814301   \n",
       "4  [-0.4009695, 20.429302, -22.221426, -33.22135,...  153.165390   \n",
       "\n",
       "                                   normed_embeddings  \\\n",
       "0  [0.041333344, 0.25355628, -0.030111149, -0.017...   \n",
       "1  [0.16911937, 0.15634705, 0.045224447, -0.11710...   \n",
       "2  [0.1343417, 0.11249763, -0.10415239, -0.038967...   \n",
       "3  [0.11533203, 0.32323492, -0.07734697, -0.07789...   \n",
       "4  [-0.0026178858, 0.13338067, -0.14508125, -0.21...   \n",
       "\n",
       "                nearest_neighbors      neighbor_classes neighbor_pred_classes  \\\n",
       "0   [6311, 7039, 295, 8215, 4123]  [12, 41, 72, 49, 23]  [20, 20, 20, 20, 20]   \n",
       "1  [9349, 5924, 8424, 1647, 3061]   [33, 7, 80, 27, 38]  [20, 20, 20, 20, 20]   \n",
       "2     [143, 51, 9836, 6406, 6063]   [6, 37, 89, 17, 31]  [20, 20, 20, 20, 20]   \n",
       "3  [4498, 9370, 1206, 8154, 6830]    [5, 85, 4, 74, 44]   [20, 20, 5, 54, 20]   \n",
       "4  [3005, 6315, 5276, 7689, 5308]    [0, 78, 92, 71, 1]  [70, 54, 70, 53, 70]   \n",
       "\n",
       "   matching_neighbors  matching_neighbor_preds  \n",
       "0                   1                        5  \n",
       "1                   1                        5  \n",
       "2                   0                        5  \n",
       "3                   0                        1  \n",
       "4                   1                        3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "9995    0\n",
      "9996    0\n",
      "9997    0\n",
      "9998    1\n",
      "9999    2\n",
      "Name: matching_neighbors, Length: 10000, dtype: int64\n",
      "Total matches: 5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11392"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.competition_score(emb_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['correct_prediction'] = emb_df['true_class']==emb_df['pred_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    10000\n",
      "Name: correct_prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(emb_df['correct_prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2461\n",
       "4    1690\n",
       "3    1542\n",
       "1    1456\n",
       "2    1427\n",
       "0    1424\n",
       "Name: matching_neighbor_preds, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df['matching_neighbor_preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6627\n",
       "1    2021\n",
       "2     745\n",
       "3     344\n",
       "4     162\n",
       "5     101\n",
       "Name: matching_neighbors, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df['matching_neighbors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f2aafffe541dce4fbde971e590718b403cdb167c5dc463f7f3d3005ad40d44b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
