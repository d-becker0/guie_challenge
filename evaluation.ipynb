{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from utils import call_backs, misc, preprocessing, evaluation_metrics\n",
    "from custom_layers.arcface_loss import ArcMarginProduct\n",
    "\n",
    "# to access cifar100\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # GENERAL\n",
    "    RANDOM_SEED = 5\n",
    "    TENSOR_LOG_DIR = 'logs'\n",
    "    SAVE_DIR = 'saved_models'\n",
    "\n",
    "    # DATA\n",
    "    INPUT_SIZE = (32,32,3)\n",
    "    NUM_CLASSES = 100 # holding out 5 classes from cifar100\n",
    "\n",
    "    # MODEL\n",
    "    OUTPUT_EMB = 64\n",
    "    MIDDLE_EMB = 256\n",
    "\n",
    "    # TRAINING\n",
    "    EPOCHS = 5#30\n",
    "    BATCH_SIZE = 32\n",
    "    LR = .0005\n",
    "\n",
    "misc.seed_everything(config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# images are of correct input_size\n",
    "print('x_train shape:', x_train.get_shape())\n",
    "assert x_train.get_shape()[-3:] == config.INPUT_SIZE\n",
    "\n",
    "print('y_train shape:', y_train.get_shape())\n",
    "# y_train has only 1 label per item in tensor\n",
    "assert y_train.get_shape()[-1:] == 1\n",
    "\n",
    "# num images == num labels\n",
    "assert y_train.get_shape()[0] == x_train.get_shape()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({19: 500, 29: 500, 0: 500, 11: 500, 1: 500, 86: 500, 90: 500, 28: 500, 23: 500, 31: 500, 39: 500, 96: 500, 82: 500, 17: 500, 71: 500, 8: 500, 97: 500, 80: 500, 74: 500, 59: 500, 70: 500, 87: 500, 84: 500, 64: 500, 52: 500, 42: 500, 47: 500, 65: 500, 21: 500, 22: 500, 81: 500, 24: 500, 78: 500, 45: 500, 49: 500, 56: 500, 76: 500, 89: 500, 73: 500, 14: 500, 9: 500, 6: 500, 20: 500, 98: 500, 36: 500, 55: 500, 72: 500, 43: 500, 51: 500, 35: 500, 83: 500, 33: 500, 27: 500, 53: 500, 92: 500, 50: 500, 15: 500, 18: 500, 46: 500, 75: 500, 38: 500, 66: 500, 77: 500, 69: 500, 95: 500, 99: 500, 93: 500, 4: 500, 61: 500, 94: 500, 68: 500, 34: 500, 32: 500, 88: 500, 67: 500, 30: 500, 62: 500, 63: 500, 40: 500, 26: 500, 48: 500, 79: 500, 85: 500, 54: 500, 44: 500, 7: 500, 12: 500, 2: 500, 41: 500, 37: 500, 13: 500, 25: 500, 10: 500, 57: 500, 5: 500, 60: 500, 91: 500, 3: 500, 58: 500, 16: 500})\n"
     ]
    }
   ],
   "source": [
    "class_count = Counter(np.array(tf.reshape(y_train, [y_train.get_shape()[0],])))\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(preprocessing.normalize).map(preprocessing.arcface_format).batch(config.BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocessing.normalize).map(preprocessing.arcface_format).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from custom_layers.arcface_loss import ArcMarginProduct\n",
    "from custom_layers.subcenter_arcface_loss import SubcenterArcMarginProduct as ArcMarginProduct\n",
    "# allows 2 inputs and 2 outputs\n",
    "\n",
    "def get_debug_model(s = 10, m = .25, k = 3):\n",
    " #------------------\n",
    "    # Definition of placeholders\n",
    "    inp = tf.keras.layers.Input(shape = config.INPUT_SIZE, name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "\n",
    "    # Definition of layers\n",
    "    \n",
    "    #TODO: reasearch filters, get better understanding\n",
    "    layer_conv1 = tf.keras.layers.Conv2D(filters = 24, kernel_size = (2,2), input_shape = config.INPUT_SIZE, activation ='relu')\n",
    "    layer_pool1 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    layer_conv2 = tf.keras.layers.Conv2D(filters = 12, kernel_size = (2,2), activation ='relu')\n",
    "    layer_pool2 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    layer_flatten = tf.keras.layers.Flatten()\n",
    "    layer_dense1 = tf.keras.layers.Dense(config.MIDDLE_EMB)\n",
    "    layer_dense2 = tf.keras.layers.Dense(config.NUM_CLASSES)\n",
    "    layer_arcface = ArcMarginProduct(n_classes=config.NUM_CLASSES, s=s, m=m, k=k)\n",
    "    layer_softmax = tf.keras.layers.Softmax(dtype='float16', name='head_output')\n",
    "\n",
    "    if config.MIDDLE_EMB != config.OUTPUT_EMB:\n",
    "        layer_adaptive_pooling = tfa.layers.AdaptiveAveragePooling1D(config.OUTPUT_EMB)\n",
    "    else:\n",
    "        layer_adaptive_pooling = tf.keras.layers.Lambda(lambda x: x)  # layer with no operation\n",
    "\n",
    "    #------------------\n",
    "    # Definition of entire model\n",
    "    backbone_output = layer_conv1(inp)\n",
    "    backbone_output = layer_pool1(backbone_output)\n",
    "    backbone_output = layer_conv2(backbone_output)\n",
    "    backbone_output = layer_pool2(backbone_output)\n",
    "    embed = layer_flatten(backbone_output)\n",
    "    embed = layer_dense1(embed)\n",
    "    \n",
    "    # Training head\n",
    "    # head_output = layer_dense2(embed)\n",
    "    head_output = layer_arcface((embed,label))\n",
    "    head_output = layer_softmax(head_output)\n",
    "    \n",
    "    # Inference\n",
    "    emb_output = layer_adaptive_pooling(embed)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [(inp, label)], outputs = [head_output, emb_output]) # whole architecture\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inp1 (InputLayer)              [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 31, 31, 24)   312         ['inp1[0][0]']                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 24)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 12)   1164        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 12)    0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 588)          0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          150784      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " inp2 (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " subcenter_arc_margin_product (  (None, 100)         51200       ['dense[0][0]',                  \n",
      " SubcenterArcMarginProduct)                                       'inp2[0][0]']                   \n",
      "                                                                                                  \n",
      " head_output (Softmax)          (None, 100)          0           ['subcenter_arc_margin_product[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " adaptive_average_pooling1d (Ad  (None, 64)          0           ['dense[0][0]']                  \n",
      " aptiveAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 203,460\n",
      "Trainable params: 203,460\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "debug_model = get_debug_model(s=32, m=.15, k=2)\n",
    "debug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10\n"
     ]
    }
   ],
   "source": [
    "debug_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = config.LR),\n",
    "        loss = {'head_output':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)},\n",
    "        metrics = {'head_output':[tf.keras.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)]},\n",
    "        )\n",
    "\n",
    "steps_per_epoch = len(train_dataset) // config.BATCH_SIZE  // 20     # \"//20\" means that the lr is update every 0.1 epoch.\n",
    "validation_steps = len(test_dataset) // config.BATCH_SIZE\n",
    "if len(test_dataset) % config.BATCH_SIZE != 0:\n",
    "    validation_steps += 1\n",
    "print(steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                        #  write_graph=True,\n",
    "                        #  write_images=True,\n",
    "                        update_freq='epoch',\n",
    "                        #  profile_batch=2,\n",
    "                        #  embeddings_freq=1\n",
    "                        )\n",
    "\n",
    "#emb_callback = call_backs.EmbeddingCallback(x_test, y_test, save_dir = log_dir+'/emb/', embedding_dim = config.OUTPUT_EMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 8.3479 - head_output_loss: 8.3479 - head_output_sparse_categorical_accuracy: 0.0000e+00 - head_output_sparse_top_k_categorical_accuracy: 8.0000e-05 - val_loss: 7.9910 - val_head_output_loss: 7.9910 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 7.9491 - head_output_loss: 7.9491 - head_output_sparse_categorical_accuracy: 8.0000e-05 - head_output_sparse_top_k_categorical_accuracy: 6.2000e-04 - val_loss: 7.8816 - val_head_output_loss: 7.8816 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0031\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 7.8422 - head_output_loss: 7.8422 - head_output_sparse_categorical_accuracy: 2.0000e-04 - head_output_sparse_top_k_categorical_accuracy: 9.2000e-04 - val_loss: 7.8211 - val_head_output_loss: 7.8211 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0031\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 7.7780 - head_output_loss: 7.7780 - head_output_sparse_categorical_accuracy: 2.6000e-04 - head_output_sparse_top_k_categorical_accuracy: 0.0012 - val_loss: 7.7902 - val_head_output_loss: 7.7902 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 7.7349 - head_output_loss: 7.7349 - head_output_sparse_categorical_accuracy: 4.0000e-04 - head_output_sparse_top_k_categorical_accuracy: 0.0013 - val_loss: 7.7629 - val_head_output_loss: 7.7629 - val_head_output_sparse_categorical_accuracy: 0.0000e+00 - val_head_output_sparse_top_k_categorical_accuracy: 0.0031\n"
     ]
    }
   ],
   "source": [
    "history = debug_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=config.EPOCHS,\n",
    "        validation_steps = validation_steps,\n",
    "        validation_data = test_dataset,\n",
    "        verbose=1,\n",
    "        #callbacks=[tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test examples: 10000\n",
      "313/313 [==============================] - 4s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Test examples:\",len(x_test))\n",
    "pred_class, pred_emb = debug_model.predict((x_test, y_test))  # I don't like this, (hacky way would be y test of -1s if non given)\n",
    "\n",
    "# argmax returns largest element's index\n",
    "pred_class = tf.argmax(pred_class, axis=1)\n",
    "true_class = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_idx</th>\n",
       "      <th>true_class</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>[25.344936, 32.39515, -4.365971, 14.029602, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>[29.77586, 20.456587, 1.2750788, -14.344727, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>[25.23964, 11.561796, -18.173515, 8.586992, -3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>[29.723036, 44.851982, -12.43706, -4.632206, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>[22.7822, 25.009588, -39.624603, -21.159386, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoy_idx  true_class  pred_class  \\\n",
       "0          0          49          20   \n",
       "1          1          33          20   \n",
       "2          2          72          20   \n",
       "3          3          51          20   \n",
       "4          4          71          70   \n",
       "\n",
       "                                           embedding  \n",
       "0  [25.344936, 32.39515, -4.365971, 14.029602, -1...  \n",
       "1  [29.77586, 20.456587, 1.2750788, -14.344727, -...  \n",
       "2  [25.23964, 11.561796, -18.173515, 8.586992, -3...  \n",
       "3  [29.723036, 44.851982, -12.43706, -4.632206, -...  \n",
       "4  [22.7822, 25.009588, -39.624603, -21.159386, -...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_data, tree = evaluation_metrics.test_embeddings(true_class,pred_class,pred_emb,config.NUM_CLASSES)\n",
    "\n",
    "emb_df = pd.DataFrame(embedding_data)\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['length']=emb_df['embedding'].apply(evaluation_metrics.dist_to_origin)\n",
    "emb_df['normed_embeddings']=emb_df['embedding']/emb_df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.build(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "emb_df['nearest_neighbors'] = emb_df['annoy_idx'].apply(lambda row: evaluation_metrics.n_neighbors(row,tree))\n",
    "emb_df['neighbor_classes'] = emb_df.apply(lambda row: evaluation_metrics.neighbor_classes(row,emb_df,true_classes=True), axis=1)\n",
    "emb_df['neighbor_pred_classes'] = emb_df.apply(lambda row: evaluation_metrics.neighbor_classes(row,emb_df,true_classes=False), axis=1)\n",
    "emb_df['matching_neighbors'] = emb_df.apply(lambda row: evaluation_metrics.matching_neighbors(row,true_classes=True), axis=1)\n",
    "emb_df['matching_neighbor_preds'] = emb_df.apply(lambda row: evaluation_metrics.matching_neighbors(row,true_classes=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_idx</th>\n",
       "      <th>true_class</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>embedding</th>\n",
       "      <th>length</th>\n",
       "      <th>normed_embeddings</th>\n",
       "      <th>nearest_neighbors</th>\n",
       "      <th>neighbor_classes</th>\n",
       "      <th>neighbor_pred_classes</th>\n",
       "      <th>matching_neighbors</th>\n",
       "      <th>matching_neighbor_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>[25.344936, 32.39515, -4.365971, 14.029602, -1...</td>\n",
       "      <td>217.510773</td>\n",
       "      <td>[0.11652267, 0.14893584, -0.020072436, 0.06450...</td>\n",
       "      <td>[7039, 1576, 9786, 4123, 3189]</td>\n",
       "      <td>[3, 17, 41, 49, 49]</td>\n",
       "      <td>[20, 20, 20, 20, 41]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>[29.77586, 20.456587, 1.2750788, -14.344727, -...</td>\n",
       "      <td>125.457184</td>\n",
       "      <td>[0.23733883, 0.16305631, 0.010163458, -0.11433...</td>\n",
       "      <td>[7704, 4048, 2035, 3329, 1462]</td>\n",
       "      <td>[65, 38, 38, 69, 67]</td>\n",
       "      <td>[41, 20, 20, 20, 20]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>[25.23964, 11.561796, -18.173515, 8.586992, -3...</td>\n",
       "      <td>164.758148</td>\n",
       "      <td>[0.15319206, 0.07017435, -0.1103042, 0.0521187...</td>\n",
       "      <td>[7248, 9942, 368, 3727, 8906]</td>\n",
       "      <td>[90, 90, 34, 89, 97]</td>\n",
       "      <td>[13, 20, 12, 13, 13]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>[29.723036, 44.851982, -12.43706, -4.632206, -...</td>\n",
       "      <td>184.316772</td>\n",
       "      <td>[0.16126062, 0.24334183, -0.067476556, -0.0251...</td>\n",
       "      <td>[369, 380, 4773, 558, 7560]</td>\n",
       "      <td>[65, 26, 78, 84, 88]</td>\n",
       "      <td>[13, 48, 58, 58, 16]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>[22.7822, 25.009588, -39.624603, -21.159386, -...</td>\n",
       "      <td>178.727844</td>\n",
       "      <td>[0.12746866, 0.13993113, -0.22170359, -0.11838...</td>\n",
       "      <td>[6315, 3005, 6635, 1494, 6502]</td>\n",
       "      <td>[70, 0, 71, 26, 23]</td>\n",
       "      <td>[54, 62, 53, 70, 53]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annoy_idx  true_class  pred_class  \\\n",
       "0          0          49          20   \n",
       "1          1          33          20   \n",
       "2          2          72          20   \n",
       "3          3          51          20   \n",
       "4          4          71          70   \n",
       "\n",
       "                                           embedding      length  \\\n",
       "0  [25.344936, 32.39515, -4.365971, 14.029602, -1...  217.510773   \n",
       "1  [29.77586, 20.456587, 1.2750788, -14.344727, -...  125.457184   \n",
       "2  [25.23964, 11.561796, -18.173515, 8.586992, -3...  164.758148   \n",
       "3  [29.723036, 44.851982, -12.43706, -4.632206, -...  184.316772   \n",
       "4  [22.7822, 25.009588, -39.624603, -21.159386, -...  178.727844   \n",
       "\n",
       "                                   normed_embeddings  \\\n",
       "0  [0.11652267, 0.14893584, -0.020072436, 0.06450...   \n",
       "1  [0.23733883, 0.16305631, 0.010163458, -0.11433...   \n",
       "2  [0.15319206, 0.07017435, -0.1103042, 0.0521187...   \n",
       "3  [0.16126062, 0.24334183, -0.067476556, -0.0251...   \n",
       "4  [0.12746866, 0.13993113, -0.22170359, -0.11838...   \n",
       "\n",
       "                nearest_neighbors      neighbor_classes neighbor_pred_classes  \\\n",
       "0  [7039, 1576, 9786, 4123, 3189]   [3, 17, 41, 49, 49]  [20, 20, 20, 20, 41]   \n",
       "1  [7704, 4048, 2035, 3329, 1462]  [65, 38, 38, 69, 67]  [41, 20, 20, 20, 20]   \n",
       "2   [7248, 9942, 368, 3727, 8906]  [90, 90, 34, 89, 97]  [13, 20, 12, 13, 13]   \n",
       "3     [369, 380, 4773, 558, 7560]  [65, 26, 78, 84, 88]  [13, 48, 58, 58, 16]   \n",
       "4  [6315, 3005, 6635, 1494, 6502]   [70, 0, 71, 26, 23]  [54, 62, 53, 70, 53]   \n",
       "\n",
       "   matching_neighbors  matching_neighbor_preds  \n",
       "0                   2                        4  \n",
       "1                   0                        4  \n",
       "2                   0                        1  \n",
       "3                   0                        0  \n",
       "4                   1                        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.competition_score(emb_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['correct_prediction'] = emb_df['true_class']==emb_df['pred_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    10000\n",
      "Name: correct_prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(emb_df['correct_prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1866\n",
       "2    1760\n",
       "0    1707\n",
       "3    1706\n",
       "4    1605\n",
       "5    1356\n",
       "Name: matching_neighbor_preds, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df['matching_neighbor_preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6864\n",
       "1    1946\n",
       "2     670\n",
       "3     309\n",
       "4     152\n",
       "5      59\n",
       "Name: matching_neighbors, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df['matching_neighbors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f2aafffe541dce4fbde971e590718b403cdb167c5dc463f7f3d3005ad40d44b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
